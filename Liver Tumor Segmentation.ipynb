{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic UNet using fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (1.21.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (1.3.4)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from pandas) (1.21.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (3.5.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from matplotlib) (8.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from matplotlib) (1.21.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from matplotlib) (3.0.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: nibabel in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (3.2.1)\n",
      "Requirement already satisfied: packaging>=14.3 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from nibabel) (21.3)\n",
      "Requirement already satisfied: numpy>=1.14 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from nibabel) (1.21.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from packaging>=14.3->nibabel) (3.0.4)\n",
      "Requirement already satisfied: imageio in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (2.13.1)\n",
      "Requirement already satisfied: pillow>=8.3.2 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from imageio) (8.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from imageio) (1.21.2)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (4.5.4.60)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from opencv-python) (1.21.2)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (7.6.5)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from ipywidgets) (6.4.1)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from ipywidgets) (3.5.2)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from ipywidgets) (1.0.2)\n",
      "Requirement already satisfied: ipython>=4.0.0 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from ipywidgets) (7.29.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from ipywidgets) (5.1.3)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: jupyter-client<8.0 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (7.0.6)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: pygments in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (2.10.0)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.4.4)\n",
      "Requirement already satisfied: backcall in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (3.0.20)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (58.0.4)\n",
      "Requirement already satisfied: decorator in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.2)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (4.9.1)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (0.3)\n",
      "Requirement already satisfied: pyzmq>=13 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (22.3.0)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from jupyter-core>=4.6.0->jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (228)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets) (3.0.2)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: notebook>=4.4.1 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from widgetsnbextension~=3.5.0->ipywidgets) (6.4.6)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (6.1.0)\n",
      "Requirement already satisfied: argon2-cffi in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (20.1.0)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.12.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.9.4)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.8.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.0.2)\n",
      "Requirement already satisfied: pywinpty>=0.5 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from terminado>=0.8.3->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.7)\n",
      "Requirement already satisfied: cffi>=1.0.0 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.15.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.21)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: testpath in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.4.3)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.3)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: bleach in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (4.0.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: async-generator in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.10)\n",
      "Requirement already satisfied: webencodings in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.0.4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from tqdm) (0.4.4)\n",
      "Requirement already satisfied: fastai in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (2.5.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from fastai) (1.3.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from fastai) (21.3)\n",
      "Requirement already satisfied: fastprogress>=0.2.4 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from fastai) (1.0.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from fastai) (1.7.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from fastai) (3.5.0)\n",
      "Requirement already satisfied: torchvision>=0.8.2 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from fastai) (0.11.1)\n",
      "Requirement already satisfied: pillow>6.0.0 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from fastai) (8.4.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from fastai) (1.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from fastai) (2.26.0)\n",
      "Requirement already satisfied: spacy<4 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from fastai) (2.3.5)\n",
      "Requirement already satisfied: torch<1.11,>=1.7.0 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from fastai) (1.10.0)\n",
      "Requirement already satisfied: fastdownload<2,>=0.0.5 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from fastai) (0.0.5)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from fastai) (6.0)\n",
      "Requirement already satisfied: fastcore<1.4,>=1.3.22 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from fastai) (1.3.26)\n",
      "Requirement already satisfied: pip in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from fastai) (21.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from fastprogress>=0.2.4->fastai) (1.21.2)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from spacy<4->fastai) (1.1.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from spacy<4->fastai) (1.0.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from spacy<4->fastai) (3.0.5)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from spacy<4->fastai) (1.0.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from spacy<4->fastai) (4.62.3)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from spacy<4->fastai) (1.0.0)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from spacy<4->fastai) (7.4.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from spacy<4->fastai) (0.8.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from spacy<4->fastai) (58.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from spacy<4->fastai) (0.7.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from spacy<4->fastai) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from requests->fastai) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from requests->fastai) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from requests->fastai) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from requests->fastai) (1.26.7)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from torch<1.11,>=1.7.0->fastai) (3.10.0.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<4->fastai) (0.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from matplotlib->fastai) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from matplotlib->fastai) (3.0.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from matplotlib->fastai) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from matplotlib->fastai) (1.3.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from matplotlib->fastai) (4.25.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->fastai) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from pandas->fastai) (2021.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from scikit-learn->fastai) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\vidhi\\.conda\\envs\\ai\\lib\\site-packages (from scikit-learn->fastai) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install nibabel\n",
    "!pip install imageio\n",
    "!pip install opencv-python\n",
    "!pip install ipywidgets\n",
    "!pip install tqdm\n",
    "!pip install fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-09-17T10:18:44.888698Z",
     "iopub.status.busy": "2020-09-17T10:18:44.888045Z",
     "iopub.status.idle": "2020-09-17T10:18:45.486180Z",
     "shell.execute_reply": "2020-09-17T10:18:45.485624Z"
    },
    "papermill": {
     "duration": 0.626614,
     "end_time": "2020-09-17T10:18:45.486328",
     "exception": false,
     "start_time": "2020-09-17T10:18:44.859714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import nibabel as nib\n",
    "import cv2\n",
    "import imageio\n",
    "from tqdm.notebook import tqdm \n",
    "from ipywidgets import *\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T10:18:45.542414Z",
     "iopub.status.busy": "2020-09-17T10:18:45.541603Z",
     "iopub.status.idle": "2020-09-17T10:20:30.156305Z",
     "shell.execute_reply": "2020-09-17T10:20:30.156768Z"
    },
    "papermill": {
     "duration": 104.648575,
     "end_time": "2020-09-17T10:20:30.156918",
     "exception": false,
     "start_time": "2020-09-17T10:18:45.508343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fastai; fastai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T10:20:30.210877Z",
     "iopub.status.busy": "2020-09-17T10:20:30.210008Z",
     "iopub.status.idle": "2020-09-17T10:20:32.013666Z",
     "shell.execute_reply": "2020-09-17T10:20:32.012732Z"
    },
    "papermill": {
     "duration": 1.832444,
     "end_time": "2020-09-17T10:20:32.013796",
     "exception": false,
     "start_time": "2020-09-17T10:20:30.181352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fastai.basics import *\n",
    "from fastai.vision.all import *\n",
    "from fastai.data.transforms import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T10:20:32.070603Z",
     "iopub.status.busy": "2020-09-17T10:20:32.069993Z",
     "iopub.status.idle": "2020-09-17T10:20:32.121073Z",
     "shell.execute_reply": "2020-09-17T10:20:32.121565Z"
    },
    "papermill": {
     "duration": 0.083103,
     "end_time": "2020-09-17T10:20:32.121688",
     "exception": false,
     "start_time": "2020-09-17T10:20:32.038585",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a meta file for nii files processing\n",
    "\n",
    "file_list = []\n",
    "for dirname, _, filenames in os.walk('C:/Data/Vidhi/College/Queens/Term1/AI/input/liver-tumor-segmentation'):\n",
    "    for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "        file_list.append((dirname,filename)) \n",
    "\n",
    "for dirname, _, filenames in os.walk('C:/Data/Vidhi/College/Queens/Term1/AI/input/liver-tumor-segmentation-part-2'):\n",
    "    for filename in filenames:\n",
    "        file_list.append((dirname,filename)) \n",
    "\n",
    "df_files = pd.DataFrame(file_list, columns =['dirname', 'filename']) \n",
    "df_files.sort_values(by=['filename'], ascending=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T10:20:32.313912Z",
     "iopub.status.busy": "2020-09-17T10:20:32.313240Z",
     "iopub.status.idle": "2020-09-17T10:20:32.327587Z",
     "shell.execute_reply": "2020-09-17T10:20:32.326462Z"
    },
    "papermill": {
     "duration": 0.180989,
     "end_time": "2020-09-17T10:20:32.327734",
     "exception": false,
     "start_time": "2020-09-17T10:20:32.146745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Map CT scan and label \n",
    "\n",
    "df_files[\"mask_dirname\"] = \"\" ; df_files[\"mask_filename\"] = \"\"\n",
    "\n",
    "for i in range(131):\n",
    "    ct = f\"volume-{i}.nii\"\n",
    "    mask = f\"segmentation-{i}.nii\"\n",
    "    \n",
    "    df_files.loc[df_files['filename'] == ct, 'mask_filename'] = mask\n",
    "    df_files.loc[df_files['filename'] == ct, 'mask_dirname'] = \"C:/Data/Vidhi/College/Queens/Term1/AI/input/liver-tumor-segmentation/segmentations\"\n",
    "\n",
    "# drop segment rows\n",
    "df_files = df_files[df_files.mask_filename != ''].sort_values(by=['filename']).reset_index(drop=True) \n",
    "print(len(df_files))\n",
    "df_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T10:20:32.388455Z",
     "iopub.status.busy": "2020-09-17T10:20:32.387699Z",
     "iopub.status.idle": "2020-09-17T10:20:32.390699Z",
     "shell.execute_reply": "2020-09-17T10:20:32.390220Z"
    },
    "papermill": {
     "duration": 0.0344,
     "end_time": "2020-09-17T10:20:32.390798",
     "exception": false,
     "start_time": "2020-09-17T10:20:32.356398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_nii(filepath):\n",
    "    '''\n",
    "    Reads .nii file and returns pixel array\n",
    "    '''\n",
    "    ct_scan = nib.load(filepath)\n",
    "    array   = ct_scan.get_fdata()\n",
    "    array   = np.rot90(np.array(array))\n",
    "    return(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T10:20:32.450884Z",
     "iopub.status.busy": "2020-09-17T10:20:32.450250Z",
     "iopub.status.idle": "2020-09-17T10:20:32.720346Z",
     "shell.execute_reply": "2020-09-17T10:20:32.721140Z"
    },
    "papermill": {
     "duration": 0.304378,
     "end_time": "2020-09-17T10:20:32.721298",
     "exception": false,
     "start_time": "2020-09-17T10:20:32.416920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read sample\n",
    "sample = 0\n",
    "sample_ct   = read_nii(df_files.loc[sample,'dirname']+\"/\"+df_files.loc[sample,'filename'])\n",
    "sample_mask  = read_nii(df_files.loc[sample,'mask_dirname']+\"/\"+df_files.loc[sample,'mask_filename'])\n",
    "sample_ct.shape, sample_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T10:20:32.780567Z",
     "iopub.status.busy": "2020-09-17T10:20:32.779552Z",
     "iopub.status.idle": "2020-09-17T10:20:32.869973Z",
     "shell.execute_reply": "2020-09-17T10:20:32.870708Z"
    },
    "papermill": {
     "duration": 0.122354,
     "end_time": "2020-09-17T10:20:32.870924",
     "exception": false,
     "start_time": "2020-09-17T10:20:32.748570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(np.amin(sample_ct), np.amax(sample_ct))\n",
    "print(np.amin(sample_mask), np.amax(sample_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T10:20:32.937029Z",
     "iopub.status.busy": "2020-09-17T10:20:32.936127Z",
     "iopub.status.idle": "2020-09-17T10:20:33.143010Z",
     "shell.execute_reply": "2020-09-17T10:20:33.143626Z"
    },
    "papermill": {
     "duration": 0.24566,
     "end_time": "2020-09-17T10:20:33.143789",
     "exception": false,
     "start_time": "2020-09-17T10:20:32.898129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocess the nii file \n",
    "# Source https://docs.fast.ai/medical.imaging\n",
    "\n",
    "dicom_windows = types.SimpleNamespace(\n",
    "    brain=(80,40),\n",
    "    subdural=(254,100),\n",
    "    stroke=(8,32),\n",
    "    brain_bone=(2800,600),\n",
    "    brain_soft=(375,40),\n",
    "    lungs=(1500,-600),\n",
    "    mediastinum=(350,50),\n",
    "    abdomen_soft=(400,50),\n",
    "    liver=(150,30),\n",
    "    spine_soft=(250,50),\n",
    "    spine_bone=(1800,400),\n",
    "    custom = (200,60)\n",
    ")\n",
    "\n",
    "@patch\n",
    "def windowed(self:Tensor, w, l):\n",
    "    px = self.clone()\n",
    "    px_min = l - w//2\n",
    "    px_max = l + w//2\n",
    "    px[px<px_min] = px_min\n",
    "    px[px>px_max] = px_max\n",
    "    return (px-px_min) / (px_max-px_min)\n",
    "\n",
    "plt.imshow(tensor(sample_ct[...,50].astype(np.float32)).windowed(*dicom_windows.liver), cmap=plt.cm.bone);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T10:20:33.218068Z",
     "iopub.status.busy": "2020-09-17T10:20:33.216319Z",
     "iopub.status.idle": "2020-09-17T10:20:33.218885Z",
     "shell.execute_reply": "2020-09-17T10:20:33.219393Z"
    },
    "papermill": {
     "duration": 0.045986,
     "end_time": "2020-09-17T10:20:33.219519",
     "exception": false,
     "start_time": "2020-09-17T10:20:33.173533",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_sample(array_list, color_map = 'nipy_spectral'):\n",
    "    '''\n",
    "    Plots and a slice with all available annotations\n",
    "    '''\n",
    "    fig = plt.figure(figsize=(18,15))\n",
    "\n",
    "    plt.subplot(1,4,1)\n",
    "    plt.imshow(array_list[0], cmap='bone')\n",
    "    plt.title('Original Image')\n",
    "    \n",
    "    plt.subplot(1,4,2)\n",
    "    plt.imshow(tensor(array_list[0].astype(np.float32)).windowed(*dicom_windows.liver), cmap='bone');\n",
    "    plt.title('Windowed Image')\n",
    "    \n",
    "    plt.subplot(1,4,3)\n",
    "    plt.imshow(array_list[1], alpha=0.5, cmap=color_map)\n",
    "    plt.title('Mask')\n",
    "    \n",
    "    plt.subplot(1,4,4)\n",
    "    plt.imshow(array_list[0], cmap='bone')\n",
    "    plt.imshow(array_list[1], alpha=0.5, cmap=color_map)\n",
    "    plt.title('Liver & Mask')\n",
    "\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T10:20:33.283632Z",
     "iopub.status.busy": "2020-09-17T10:20:33.282644Z",
     "iopub.status.idle": "2020-09-17T10:20:33.936065Z",
     "shell.execute_reply": "2020-09-17T10:20:33.936583Z"
    },
    "papermill": {
     "duration": 0.687943,
     "end_time": "2020-09-17T10:20:33.936722",
     "exception": false,
     "start_time": "2020-09-17T10:20:33.248779",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample=50\n",
    "sample_slice = tensor(sample_ct[...,sample].astype(np.float32))\n",
    "\n",
    "plot_sample([sample_ct[...,sample], sample_mask[...,sample]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T10:20:34.007851Z",
     "iopub.status.busy": "2020-09-17T10:20:34.007182Z",
     "iopub.status.idle": "2020-09-17T10:20:34.019459Z",
     "shell.execute_reply": "2020-09-17T10:20:34.018967Z"
    },
    "papermill": {
     "duration": 0.050249,
     "end_time": "2020-09-17T10:20:34.019562",
     "exception": false,
     "start_time": "2020-09-17T10:20:33.969313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check the mask values\n",
    "mask = Image.fromarray(sample_mask[...,sample].astype('uint8'), mode=\"L\")\n",
    "unique, counts = np.unique(mask, return_counts=True)\n",
    "print( np.array((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T10:20:34.106191Z",
     "iopub.status.busy": "2020-09-17T10:20:34.105042Z",
     "iopub.status.idle": "2020-09-17T10:20:34.259924Z",
     "shell.execute_reply": "2020-09-17T10:20:34.260421Z"
    },
    "papermill": {
     "duration": 0.208373,
     "end_time": "2020-09-17T10:20:34.260558",
     "exception": false,
     "start_time": "2020-09-17T10:20:34.052185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocessing functions\n",
    "# Source https://docs.fast.ai/medical.imaging\n",
    "\n",
    "class TensorCTScan(TensorImageBW): _show_args = {'cmap':'bone'}\n",
    "\n",
    "@patch\n",
    "def freqhist_bins(self:Tensor, n_bins=100):\n",
    "    \"A function to split the range of pixel values into groups, such that each group has around the same number of pixels\"\n",
    "    imsd = self.view(-1).sort()[0]\n",
    "    t = torch.cat([tensor([0.001]),\n",
    "                   torch.arange(n_bins).float()/n_bins+(1/2/n_bins),\n",
    "                   tensor([0.999])])\n",
    "    t = (len(imsd)*t).long()\n",
    "    return imsd[t].unique()\n",
    "    \n",
    "@patch\n",
    "def hist_scaled(self:Tensor, brks=None):\n",
    "    \"Scales a tensor using `freqhist_bins` to values between 0 and 1\"\n",
    "    if self.device.type=='cuda': return self.hist_scaled_pt(brks)\n",
    "    if brks is None: brks = self.freqhist_bins()\n",
    "    ys = np.linspace(0., 1., len(brks))\n",
    "    x = self.numpy().flatten()\n",
    "    x = np.interp(x, brks.numpy(), ys)\n",
    "    return tensor(x).reshape(self.shape).clamp(0.,1.)\n",
    "    \n",
    "    \n",
    "@patch\n",
    "def to_nchan(x:Tensor, wins, bins=None):\n",
    "    res = [x.windowed(*win) for win in wins]\n",
    "    if not isinstance(bins,int) or bins!=0: res.append(x.hist_scaled(bins).clamp(0,1))\n",
    "    dim = [0,1][x.dim()==3]\n",
    "    return TensorCTScan(torch.stack(res, dim=dim))\n",
    "\n",
    "@patch\n",
    "def save_jpg(x:(Tensor), path, wins, bins=None, quality=90):\n",
    "    fn = Path(path).with_suffix('.jpg')\n",
    "    x = (x.to_nchan(wins, bins)*255).byte()\n",
    "    im = Image.fromarray(x.permute(1,2,0).numpy(), mode=['RGB','CMYK'][x.shape[0]==4])\n",
    "    im.save(fn, quality=quality)\n",
    "\n",
    "_,axs=subplots(1,1)\n",
    "\n",
    "sample_slice.save_jpg('test.jpg', [dicom_windows.liver,dicom_windows.custom])\n",
    "show_image(Image.open('test.jpg'), ax=axs[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T10:20:34.343302Z",
     "iopub.status.busy": "2020-09-17T10:20:34.342437Z",
     "iopub.status.idle": "2020-09-17T10:31:09.233494Z",
     "shell.execute_reply": "2020-09-17T10:31:09.234232Z"
    },
    "papermill": {
     "duration": 634.938284,
     "end_time": "2020-09-17T10:31:09.234475",
     "exception": false,
     "start_time": "2020-09-17T10:20:34.296191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make custom JPG files for Unet training\n",
    "# Total number of 131 nii files contains 67072 slices \n",
    "\n",
    "GENERATE_JPG_FILES = True   # warning: generation takes ~ 1h\n",
    "\n",
    "if (GENERATE_JPG_FILES) :\n",
    "    \n",
    "    path = Path(\".\")\n",
    "\n",
    "    os.makedirs('train_images',exist_ok=True)\n",
    "    os.makedirs('train_masks',exist_ok=True)\n",
    "\n",
    "    for ii in tqdm(range(0,len(df_files),3)): # take 1/3 nii files for training\n",
    "        curr_ct        = read_nii(df_files.loc[ii,'dirname']+\"/\"+df_files.loc[ii,'filename'])\n",
    "        curr_mask      = read_nii(df_files.loc[ii,'mask_dirname']+\"/\"+df_files.loc[ii,'mask_filename'])\n",
    "        curr_file_name = str(df_files.loc[ii,'filename']).split('.')[0]\n",
    "        curr_dim       = curr_ct.shape[2] # 512, 512, curr_dim\n",
    "\n",
    "        for curr_slice in range(0,curr_dim,2): # export every 2nd slice for training\n",
    "            data = tensor(curr_ct[...,curr_slice].astype(np.float32))\n",
    "            mask = Image.fromarray(curr_mask[...,curr_slice].astype('uint8'), mode=\"L\")\n",
    "            data.save_jpg(f\"train_images/{curr_file_name}_slice_{curr_slice}.jpg\", [dicom_windows.liver,dicom_windows.custom])\n",
    "            mask.save(f\"train_masks/{curr_file_name}_slice_{curr_slice}_mask.png\")\n",
    "else:\n",
    "    \n",
    "    path = Path(\"C:/Data/Vidhi/College/Queens/Term1/AI/input/liver-segmentation-with-fastai-v2\") # read jpg from saved kernel output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.036607,
     "end_time": "2020-09-17T10:31:09.310409",
     "exception": false,
     "start_time": "2020-09-17T10:31:09.273802",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T10:31:09.400348Z",
     "iopub.status.busy": "2020-09-17T10:31:09.399524Z",
     "iopub.status.idle": "2020-09-17T10:31:09.584315Z",
     "shell.execute_reply": "2020-09-17T10:31:09.583725Z"
    },
    "papermill": {
     "duration": 0.231151,
     "end_time": "2020-09-17T10:31:09.584435",
     "exception": false,
     "start_time": "2020-09-17T10:31:09.353284",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bs = 16\n",
    "im_size = 128\n",
    "\n",
    "codes = np.array([\"background\",\"liver\",\"tumor\"])\n",
    "    \n",
    "def get_x(fname:Path): return fname\n",
    "def label_func(x): return path/'train_masks'/f'{x.stem}_mask.png'\n",
    "\n",
    "tfms = [IntToFloatTensor(),Normalize()]\n",
    "\n",
    "db = DataBlock(blocks=(ImageBlock(),MaskBlock(codes)),  #codes = {\"Backround\": 0,\"Liver\": 1,\"Tumor\": 2}\n",
    "               batch_tfms=tfms,\n",
    "               splitter=RandomSplitter(),\n",
    "               item_tfms=[Resize(im_size)],\n",
    "               get_items=get_image_files,\n",
    "               get_y=label_func\n",
    "              )\n",
    "\n",
    "ds = db.datasets(source=path/'train_images')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T10:31:09.668306Z",
     "iopub.status.busy": "2020-09-17T10:31:09.667413Z",
     "iopub.status.idle": "2020-09-17T10:31:09.846780Z",
     "shell.execute_reply": "2020-09-17T10:31:09.847472Z"
    },
    "papermill": {
     "duration": 0.224794,
     "end_time": "2020-09-17T10:31:09.847616",
     "exception": false,
     "start_time": "2020-09-17T10:31:09.622822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx=20\n",
    "imgs = [ds[idx][0],ds[idx][1]]\n",
    "fig,axs = plt.subplots(1, 2)\n",
    "for i,ax in enumerate(axs.flatten()):\n",
    "    ax.axis('off')\n",
    "    ax.imshow(imgs[i]) #, cmap='gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T10:31:09.939468Z",
     "iopub.status.busy": "2020-09-17T10:31:09.938646Z",
     "iopub.status.idle": "2020-09-17T10:31:09.959487Z",
     "shell.execute_reply": "2020-09-17T10:31:09.958878Z"
    },
    "papermill": {
     "duration": 0.068728,
     "end_time": "2020-09-17T10:31:09.959612",
     "exception": false,
     "start_time": "2020-09-17T10:31:09.890884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique, counts = np.unique(array(ds[idx][1]), return_counts=True)\n",
    "\n",
    "print( np.array((unique, counts)).T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T10:31:10.049785Z",
     "iopub.status.busy": "2020-09-17T10:31:10.048920Z",
     "iopub.status.idle": "2020-09-17T10:31:20.077773Z",
     "shell.execute_reply": "2020-09-17T10:31:20.078267Z"
    },
    "papermill": {
     "duration": 10.074493,
     "end_time": "2020-09-17T10:31:20.078414",
     "exception": false,
     "start_time": "2020-09-17T10:31:10.003921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dls = db.dataloaders(path/'train_images',bs = bs) #, num_workers=0\n",
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cyclical Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T10:31:20.179754Z",
     "iopub.status.busy": "2020-09-17T10:31:20.178995Z",
     "iopub.status.idle": "2020-09-17T10:31:20.182377Z",
     "shell.execute_reply": "2020-09-17T10:31:20.182817Z"
    },
    "papermill": {
     "duration": 0.05798,
     "end_time": "2020-09-17T10:31:20.182943",
     "exception": false,
     "start_time": "2020-09-17T10:31:20.124963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def foreground_acc(inp, targ, bkg_idx=0, axis=1):  # exclude a background from metric\n",
    "    \"Computes non-background accuracy for multiclass segmentation\"\n",
    "    targ = targ.squeeze(1)\n",
    "    mask = targ != bkg_idx\n",
    "    return (inp.argmax(dim=axis)[mask]==targ[mask]).float().mean() \n",
    "\n",
    "def cust_foreground_acc(inp, targ):  # # include a background into the metric\n",
    "    return foreground_acc(inp=inp, targ=targ, bkg_idx=3, axis=1) # 3 is a dummy value to include the background which is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T10:31:20.295552Z",
     "iopub.status.busy": "2020-09-17T10:31:20.294822Z",
     "iopub.status.idle": "2020-09-17T10:31:24.879631Z",
     "shell.execute_reply": "2020-09-17T10:31:24.879073Z"
    },
    "papermill": {
     "duration": 4.649991,
     "end_time": "2020-09-17T10:31:24.879751",
     "exception": false,
     "start_time": "2020-09-17T10:31:20.229760",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "learn = unet_learner(dls, resnet34, loss_func=CrossEntropyLossFlat(axis=1), metrics=[foreground_acc, cust_foreground_acc]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T10:31:24.981016Z",
     "iopub.status.busy": "2020-09-17T10:31:24.980356Z",
     "iopub.status.idle": "2020-09-17T10:31:24.984419Z",
     "shell.execute_reply": "2020-09-17T10:31:24.983866Z"
    },
    "papermill": {
     "duration": 0.055128,
     "end_time": "2020-09-17T10:31:24.984559",
     "exception": false,
     "start_time": "2020-09-17T10:31:24.929431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T10:31:25.087912Z",
     "iopub.status.busy": "2020-09-17T10:31:25.087147Z",
     "iopub.status.idle": "2020-09-17T10:41:38.763294Z",
     "shell.execute_reply": "2020-09-17T10:41:38.762579Z"
    },
    "papermill": {
     "duration": 613.73016,
     "end_time": "2020-09-17T10:41:38.763443",
     "exception": false,
     "start_time": "2020-09-17T10:31:25.033283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "learn.fine_tune(5, wd=0.1, cbs=SaveModelCallback() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T10:41:38.878113Z",
     "iopub.status.busy": "2020-09-17T10:41:38.877191Z",
     "iopub.status.idle": "2020-09-17T10:41:39.530716Z",
     "shell.execute_reply": "2020-09-17T10:41:39.531281Z"
    },
    "papermill": {
     "duration": 0.715437,
     "end_time": "2020-09-17T10:41:39.531453",
     "exception": false,
     "start_time": "2020-09-17T10:41:38.816016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "learn.show_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T10:41:39.671067Z",
     "iopub.status.busy": "2020-09-17T10:41:39.670046Z",
     "iopub.status.idle": "2020-09-17T10:41:40.241416Z",
     "shell.execute_reply": "2020-09-17T10:41:40.240838Z"
    },
    "papermill": {
     "duration": 0.650879,
     "end_time": "2020-09-17T10:41:40.241532",
     "exception": false,
     "start_time": "2020-09-17T10:41:39.590653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "learn.export(path/f'Liver_segmentation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T10:41:40.361909Z",
     "iopub.status.busy": "2020-09-17T10:41:40.361182Z",
     "iopub.status.idle": "2020-09-17T10:41:40.366000Z",
     "shell.execute_reply": "2020-09-17T10:41:40.365482Z"
    },
    "papermill": {
     "duration": 0.068704,
     "end_time": "2020-09-17T10:41:40.366108",
     "exception": false,
     "start_time": "2020-09-17T10:41:40.297404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import gc\n",
    "# del learn\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.056873,
     "end_time": "2020-09-17T10:41:40.480160",
     "exception": false,
     "start_time": "2020-09-17T10:41:40.423287",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T10:41:40.603734Z",
     "iopub.status.busy": "2020-09-17T10:41:40.602589Z",
     "iopub.status.idle": "2020-09-17T10:41:40.923756Z",
     "shell.execute_reply": "2020-09-17T10:41:40.922711Z"
    },
    "papermill": {
     "duration": 0.387006,
     "end_time": "2020-09-17T10:41:40.923896",
     "exception": false,
     "start_time": "2020-09-17T10:41:40.536890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load saved model\n",
    "if (GENERATE_JPG_FILES) :\n",
    "    \n",
    "    tfms = [Resize(im_size), IntToFloatTensor(),Normalize()]\n",
    "    learn0               = load_learner(path/f'Liver_segmentation',cpu=False )\n",
    "    learn0.dls.transform = tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T10:41:41.056342Z",
     "iopub.status.busy": "2020-09-17T10:41:41.055494Z",
     "iopub.status.idle": "2020-09-17T10:41:41.059363Z",
     "shell.execute_reply": "2020-09-17T10:41:41.058694Z"
    },
    "papermill": {
     "duration": 0.076101,
     "end_time": "2020-09-17T10:41:41.059470",
     "exception": false,
     "start_time": "2020-09-17T10:41:40.983369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def nii_tfm(fn,wins): \n",
    "\n",
    "    test_nii  = read_nii(fn)\n",
    "    curr_dim  = test_nii.shape[2] # 512, 512, curr_dim\n",
    "    slices = []\n",
    "    \n",
    "    for curr_slice in range(curr_dim):\n",
    "        data = tensor(test_nii[...,curr_slice].astype(np.float32))\n",
    "        data = (data.to_nchan(wins)*255).byte()\n",
    "        slices.append(TensorImage(data))\n",
    "                      \n",
    "    return slices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T10:41:41.185516Z",
     "iopub.status.busy": "2020-09-17T10:41:41.184650Z",
     "iopub.status.idle": "2020-09-17T10:41:49.995815Z",
     "shell.execute_reply": "2020-09-17T10:41:49.995026Z"
    },
    "papermill": {
     "duration": 8.877605,
     "end_time": "2020-09-17T10:41:49.995953",
     "exception": false,
     "start_time": "2020-09-17T10:41:41.118348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tst = 20\n",
    "\n",
    "test_nii   = read_nii(df_files.loc[tst,'dirname']+\"/\"+df_files.loc[tst,'filename'])\n",
    "test_mask  = read_nii(df_files.loc[tst,'mask_dirname']+\"/\"+df_files.loc[tst,'mask_filename'])\n",
    "print(test_nii.shape)\n",
    "\n",
    "test_slice_idx = 500\n",
    "\n",
    "sample_slice = tensor(test_nii[...,test_slice_idx].astype(np.float32))\n",
    "\n",
    "plot_sample([test_nii[...,test_slice_idx], test_mask[...,test_slice_idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T10:41:50.154399Z",
     "iopub.status.busy": "2020-09-17T10:41:50.153478Z",
     "iopub.status.idle": "2020-09-17T10:42:29.803419Z",
     "shell.execute_reply": "2020-09-17T10:42:29.804090Z"
    },
    "papermill": {
     "duration": 39.726522,
     "end_time": "2020-09-17T10:42:29.804300",
     "exception": false,
     "start_time": "2020-09-17T10:41:50.077778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare a nii test file for prediction \n",
    "\n",
    "test_files = nii_tfm(df_files.loc[tst,'dirname']+\"/\"+df_files.loc[tst,'filename'],[dicom_windows.liver, dicom_windows.custom])\n",
    "print(\"Number of test slices: \",len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T10:42:29.945500Z",
     "iopub.status.busy": "2020-09-17T10:42:29.944473Z",
     "iopub.status.idle": "2020-09-17T10:42:30.093734Z",
     "shell.execute_reply": "2020-09-17T10:42:30.094370Z"
    },
    "papermill": {
     "duration": 0.224064,
     "end_time": "2020-09-17T10:42:30.094508",
     "exception": false,
     "start_time": "2020-09-17T10:42:29.870444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check an input for a test file\n",
    "show_image(test_files[test_slice_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T10:42:30.264315Z",
     "iopub.status.busy": "2020-09-17T10:42:30.259249Z",
     "iopub.status.idle": "2020-09-17T10:42:39.403413Z",
     "shell.execute_reply": "2020-09-17T10:42:39.402850Z"
    },
    "papermill": {
     "duration": 9.239444,
     "end_time": "2020-09-17T10:42:39.403540",
     "exception": false,
     "start_time": "2020-09-17T10:42:30.164096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get predictions for a Test file\n",
    "\n",
    "test_dl = learn0.dls.test_dl(test_files)\n",
    "preds, y = learn0.get_preds(dl=test_dl)\n",
    "\n",
    "predicted_mask = np.argmax(preds, axis=1)\n",
    "plt.imshow(predicted_mask[test_slice_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T10:42:39.553408Z",
     "iopub.status.busy": "2020-09-17T10:42:39.550943Z",
     "iopub.status.idle": "2020-09-17T10:42:39.557319Z",
     "shell.execute_reply": "2020-09-17T10:42:39.556733Z"
    },
    "papermill": {
     "duration": 0.080409,
     "end_time": "2020-09-17T10:42:39.557422",
     "exception": false,
     "start_time": "2020-09-17T10:42:39.477013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "a=np.array(predicted_mask[test_slice_idx])\n",
    "np.amin(a),np.amax(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Various Metrics calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = dls.valid_ds\n",
    "# # dir(learn)\n",
    "# # outputs = learn.pred_batch(ds_type=DatasetType.Valid)\n",
    "# # outputs.shape\n",
    "# t = learn.dls.valid\n",
    "# outputs = learn.get_preds()\n",
    "# outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # outputs[0].shape # -- these are individual predictions for each class, so 3 channels -- 2018 images\n",
    "# # outputs[1].shape # -- these are same predictions merged into 1 channel --  2018 images\n",
    "# outputs[0][0][0]\n",
    "# # I'll be back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(outputs[1][66])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_np(ds[66][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import jaccard_score as jsc\n",
    "\n",
    "# #average metrics\n",
    "# accuracy_mean = []\n",
    "# precision_mean = []\n",
    "# recall_mean = []\n",
    "# branching_f_mean = []\n",
    "# miss_f_mean = []\n",
    "# detection_p_mean = []\n",
    "# iou_mean = []\n",
    "# quality_p_mean = []\n",
    "\n",
    "# for i in range(0,2):\n",
    "#     # converting tensors to numpy arrays\n",
    "#     ground_truth = to_np(outputs)\n",
    "#     prediction = to_np(outputs[i][1].sigmoid()>0.95)\n",
    "    \n",
    "#     # converting ground truth to binary/boolean arrays for calculating metrics\n",
    "#     gt = np.array(ground_truth[0], dtype=bool)\n",
    "#     # prediction is already a binary array\n",
    "    \n",
    "#     if (not gt.sum()) or (not prediction.sum()):\n",
    "#         continue\n",
    "    \n",
    "#     #getting TP, TN, FP, FN\n",
    "#     TP = (gt & prediction).sum()\n",
    "#     TN = np.invert(gt | prediction).sum()\n",
    "#     FP = (prediction & np.invert(gt)).sum()\n",
    "#     FN = (np.invert(prediction) & gt).sum()\n",
    "    \n",
    "#     # calculating metrics\n",
    "#     iou = jsc(ground_truth[0].reshape(-1), prediction.reshape(-1))\n",
    "#     branching_factor = FP/TP\n",
    "#     miss_factor = FN/TP\n",
    "#     detection_percentage = 100*(TP/(TP+FN))\n",
    "#     quality_percentage = 100*(TP/(TP+FP+FN))\n",
    "#     accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "#     precision = TP/(TP+FN)\n",
    "#     recall = TP/(TP+FP)\n",
    "    \n",
    "#     accuracy_mean.append(accuracy)\n",
    "#     precision_mean.append(precision)\n",
    "#     recall_mean.append(recall)\n",
    "#     branching_f_mean.append(branching_factor)\n",
    "#     miss_f_mean.append(miss_factor)\n",
    "#     detection_p_mean.append(detection_percentage)\n",
    "#     quality_p_mean.append(quality_percentage)\n",
    "#     iou_mean.append(iou)\n",
    "    \n",
    "#     fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(15,5))\n",
    "    \n",
    "#     fig.suptitle(\"IoU: \" + str(round(iou, 3)))\n",
    "    \n",
    "#     ax1.set_title('Input RGB Image')\n",
    "#     data.valid_ds.x[i].show(ax=ax1)\n",
    "    \n",
    "#     ax2.set_title('Prediction')\n",
    "#     data.valid_ds.x[i].show(ax=ax2)\n",
    "#     ax2.imshow(prediction, alpha=0.5)\n",
    "    \n",
    "#     ax3.set_title('Ground Truth')\n",
    "#     data.valid_ds.x[i].show(ax=ax3)\n",
    "#     ax3.imshow(ground_truth[0], alpha=0.5)\n",
    "#     plt.show()\n",
    "    \n",
    "#     print(\"Accuracy: \", round(accuracy,3))\n",
    "#     print(\"Precision: \", round(precision,3))\n",
    "#     print(\"Recall: \", round(recall,3))\n",
    "#     print(\"Branching Factor: \", round(branching_factor,3))\n",
    "#     print(\"Miss Factor: \", round(miss_factor,3))\n",
    "#     print(\"Detection Percentage: \", round(detection_percentage,3))\n",
    "#     print(\"Quality Percentage: \", round(quality_percentage,3))\n",
    "#     print(\"************************\".center(118))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation for Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sample_ct\n",
    "y = sample_mask\n",
    "\n",
    "X = X.reshape(X.shape[0] * X.shape[1], X.shape[2])\n",
    "y = y.reshape(y.shape[0] * y.shape[1], y.shape[2])\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.multioutput import MultiOutputClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Training and Test set from data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Random Forest Classification to the Training set\n",
    "rf = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42)\n",
    "classifier = MultiOutputClassifier(rf, n_jobs = -1)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Our prediction accuracy for Random Forest is: {score}%'.format(score=classifier.score(X_test, y_test) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Our prediction accuracy for Decision Tree is: {score}%'.format(score=clf.score(X_test, y_test) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "papermill": {
   "duration": 1440.43809,
   "end_time": "2020-09-17T10:42:41.266080",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-09-17T10:18:40.827990",
   "version": "2.1.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0afcf9161e554dc788367a03e8d54e9b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "14d8e7a9c6a34db5b516fc24bcc7ceaa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_16476eb9891a462ba8a6127de985ad5e",
       "style": "IPY_MODEL_801949e8bbd3452aafea1fa8868db09b",
       "value": " 83.3M/83.3M [01:28&lt;00:00, 983kB/s]"
      }
     },
     "16476eb9891a462ba8a6127de985ad5e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "18eb64b4292044ecacd5048adfd8e05b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_f0056e04b53d409096380d13d8071ce1",
       "max": 87319819,
       "style": "IPY_MODEL_e704e817fa384549a39ef1ea213a734a",
       "value": 87319819
      }
     },
     "2ef798b46fa041069164db1e85f04b0a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_990941340390416bafe1acfc33438ed5",
        "IPY_MODEL_14d8e7a9c6a34db5b516fc24bcc7ceaa"
       ],
       "layout": "IPY_MODEL_b7fec88223a7439c8bedf011c7f3a9ac"
      }
     },
     "3e44ca3857044e0399de463800625626": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3fc3d42df746438896e9abb4b6088e74": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_a3dbbd070f884803b2e5812dc9e5ac59",
       "style": "IPY_MODEL_6f6b8f24b6a840c69761b95e067f94dd",
       "value": " 44/44 [12:34&lt;00:00, 17.14s/it]"
      }
     },
     "4e18ce5181d04cbcac142c26d08244ae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "556033121fb5490a981df792b9ebb3fc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_b5eb22faadb8476db8c5222803315cbe",
       "style": "IPY_MODEL_b63272f8ee5f499e931e2ce5269194be",
       "value": "100%"
      }
     },
     "59b7fcc6ddd84f43ac984c35e3eef0e7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "63dcd0210f214dff809c8377daa03a95": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6eec189d0d0c425b8a68d5bdd45d0b88": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6f1896242f154c30a68e7791bbf1ffa1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_0afcf9161e554dc788367a03e8d54e9b",
       "max": 44,
       "style": "IPY_MODEL_8f6af81876b54bd38ed4d72a938e5d29",
       "value": 44
      }
     },
     "6f6b8f24b6a840c69761b95e067f94dd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "73fcad2a5902445c8a0d6f29ad3c051d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "801949e8bbd3452aafea1fa8868db09b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "85be136a644f49dcba4bf676584a231c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8a9c6b0208114119a8062bb91f2aa8f4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8f6af81876b54bd38ed4d72a938e5d29": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "990941340390416bafe1acfc33438ed5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "100%",
       "layout": "IPY_MODEL_63dcd0210f214dff809c8377daa03a95",
       "max": 87306240,
       "style": "IPY_MODEL_59b7fcc6ddd84f43ac984c35e3eef0e7",
       "value": 87306240
      }
     },
     "9da11e4a7d9a48e9b9f10f68556aa9d0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a3dbbd070f884803b2e5812dc9e5ac59": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "aa048dafdc4a41c497f898cb9cee242a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "aa2a851b3b514ce3b4755e2e99127fff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_b9608f4dd4f54736a56193e5b452c3df",
        "IPY_MODEL_3fc3d42df746438896e9abb4b6088e74"
       ],
       "layout": "IPY_MODEL_9da11e4a7d9a48e9b9f10f68556aa9d0"
      }
     },
     "b5eb22faadb8476db8c5222803315cbe": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b63272f8ee5f499e931e2ce5269194be": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "b7fec88223a7439c8bedf011c7f3a9ac": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b9608f4dd4f54736a56193e5b452c3df": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "100%",
       "layout": "IPY_MODEL_85be136a644f49dcba4bf676584a231c",
       "max": 44,
       "style": "IPY_MODEL_e52a98e71f4240e1a66c14e88b2d9531",
       "value": 44
      }
     },
     "bbb2ec79d9554c0aba676c5725ef62d1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_6eec189d0d0c425b8a68d5bdd45d0b88",
       "style": "IPY_MODEL_4e18ce5181d04cbcac142c26d08244ae",
       "value": " 83.3M/83.3M [00:48&lt;00:00, 1.97MB/s]"
      }
     },
     "c4b0d7e3ad394b6b83db2df923106dec": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d71721d226f94faeb81d397c5a9f8818": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_556033121fb5490a981df792b9ebb3fc",
        "IPY_MODEL_6f1896242f154c30a68e7791bbf1ffa1",
        "IPY_MODEL_f9056b23486b4ce6b93d5b9bdec5a937"
       ],
       "layout": "IPY_MODEL_3e44ca3857044e0399de463800625626"
      }
     },
     "e52a98e71f4240e1a66c14e88b2d9531": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "e704e817fa384549a39ef1ea213a734a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "f0056e04b53d409096380d13d8071ce1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f0d86e98852545bea99108ecb04aec86": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "f603652d2ebb49cfb08e183b107b3011": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_ff1d3901f6b3469e932579caabded2ed",
        "IPY_MODEL_18eb64b4292044ecacd5048adfd8e05b",
        "IPY_MODEL_bbb2ec79d9554c0aba676c5725ef62d1"
       ],
       "layout": "IPY_MODEL_aa048dafdc4a41c497f898cb9cee242a"
      }
     },
     "f9056b23486b4ce6b93d5b9bdec5a937": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_c4b0d7e3ad394b6b83db2df923106dec",
       "style": "IPY_MODEL_73fcad2a5902445c8a0d6f29ad3c051d",
       "value": " 44/44 [16:23&lt;00:00, 22.97s/it]"
      }
     },
     "ff1d3901f6b3469e932579caabded2ed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_8a9c6b0208114119a8062bb91f2aa8f4",
       "style": "IPY_MODEL_f0d86e98852545bea99108ecb04aec86",
       "value": "100%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
